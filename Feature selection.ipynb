{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca62424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31887c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b4c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Santander customer satisfaction dataset from Kaggle\n",
    "\n",
    "X_train = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\train.csv\", nrows=35000)\n",
    "\n",
    "X_test = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\test.csv\", nrows=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1452800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop TARGET label from X_train\n",
    "\n",
    "X_train.drop(labels=['TARGET'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c373942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of training and test sets\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b9418",
   "metadata": {},
   "source": [
    "# Using variance threshold from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdb024",
   "metadata": {},
   "source": [
    "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fb8cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn variancethreshold to find constant features\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(X_train)  # fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91eadc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features are retained\n",
    "# if we sum over get_support, we get the number of features that are not constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14781adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate way of finding non-constant features\n",
    "len(X_train.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1249b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var18_0',\n",
       " 'ind_var18',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var34_0',\n",
       " 'ind_var34',\n",
       " 'ind_var41',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var18_0',\n",
       " 'num_var18',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var34_0',\n",
       " 'num_var34',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var18',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var34',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var18_ult1',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_amort_var34_ult1',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var17_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace3',\n",
       " 'saldo_medio_var29_hace3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the constant features\n",
    "print(\n",
    "    len([\n",
    "        x for x in X_train.columns\n",
    "        if x not in X_train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534069c",
   "metadata": {},
   "source": [
    "We can see that there are 51 columns / variables that are constant. This means that 51 variables show the same value, just one value, for all the observations of the training set.\n",
    "\n",
    "We then use the transform function to reduce the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fefc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then drop these columns from the train and test sets\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b3eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 319), (15000, 319))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of training and test set\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461b057",
   "metadata": {},
   "source": [
    "# Remove quasi-constant features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885e571",
   "metadata": {},
   "source": [
    "Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little if any information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So we should be careful when removing these type of features. Identifying and removing quasi-constant features, is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "To identify quasi-constant features, we can once again use the VarianceThreshold function from sklearn.\n",
    "\n",
    "Here I will demonstrate how to identify quasi-constant features using the Santander Customer Satisfaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36dda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Santander customer satisfaction dataset from Kaggle\n",
    "\n",
    "X_train = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\train.csv\", nrows=35000)\n",
    "\n",
    "X_test = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\test.csv\", nrows=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b04f10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop TARGET label from X_train\n",
    "\n",
    "X_train.drop(labels=['TARGET'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667fab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of training and test sets\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b36619",
   "metadata": {},
   "source": [
    "# Removing quasi-constant features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1e1e6",
   "metadata": {},
   "source": [
    "# Using variance threshold from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfc25c",
   "metadata": {},
   "source": [
    "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples.\n",
    "\n",
    "Here, I will change the default threshold to remove almost / quasi-constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae4c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
    "\n",
    "sel.fit(X_train)  # fit finds the features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5974d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features \n",
    "# are retained. If we sum over get_support, we get the number\n",
    "# of features that are not quasi-constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99679134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative way of doing the above operation:\n",
    "len(X_train.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e338bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var1',\n",
       " 'ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var6_0',\n",
       " 'ind_var6',\n",
       " 'ind_var13_largo',\n",
       " 'ind_var13_medio_0',\n",
       " 'ind_var13_medio',\n",
       " 'ind_var14',\n",
       " 'ind_var17_0',\n",
       " 'ind_var17',\n",
       " 'ind_var18_0',\n",
       " 'ind_var18',\n",
       " 'ind_var19',\n",
       " 'ind_var20_0',\n",
       " 'ind_var20',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var29_0',\n",
       " 'ind_var29',\n",
       " 'ind_var30_0',\n",
       " 'ind_var31_0',\n",
       " 'ind_var31',\n",
       " 'ind_var32_cte',\n",
       " 'ind_var32_0',\n",
       " 'ind_var32',\n",
       " 'ind_var33_0',\n",
       " 'ind_var33',\n",
       " 'ind_var34_0',\n",
       " 'ind_var34',\n",
       " 'ind_var40',\n",
       " 'ind_var41',\n",
       " 'ind_var39',\n",
       " 'ind_var44_0',\n",
       " 'ind_var44',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var6_0',\n",
       " 'num_var6',\n",
       " 'num_var13_medio_0',\n",
       " 'num_var13_medio',\n",
       " 'num_var18_0',\n",
       " 'num_var18',\n",
       " 'num_op_var40_hace3',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var29_0',\n",
       " 'num_var29',\n",
       " 'num_var33',\n",
       " 'num_var34_0',\n",
       " 'num_var34',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var18',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var34',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'delta_imp_aport_var33_1y3',\n",
       " 'delta_num_aport_var33_1y3',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var18_ult1',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_amort_var34_ult1',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var17_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'ind_var7_emit_ult1',\n",
       " 'ind_var7_recib_ult1',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_aport_var33_hace3',\n",
       " 'num_aport_var33_ult1',\n",
       " 'num_var7_emit_ult1',\n",
       " 'num_meses_var13_medio_ult3',\n",
       " 'num_meses_var17_ult3',\n",
       " 'num_meses_var29_ult3',\n",
       " 'num_meses_var33_ult3',\n",
       " 'num_meses_var44_ult3',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var13_ult1',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_reemb_var33_ult1',\n",
       " 'num_trasp_var17_in_hace3',\n",
       " 'num_trasp_var17_in_ult1',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var17_out_ult1',\n",
       " 'num_trasp_var33_in_hace3',\n",
       " 'num_trasp_var33_in_ult1',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'num_trasp_var33_out_ult1',\n",
       " 'num_venta_var44_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace3',\n",
       " 'saldo_medio_var29_hace3']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally we can print the quasi-constant features\n",
    "print(\n",
    "    len([\n",
    "        x for x in X_train.columns\n",
    "        if x not in X_train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b66c0",
   "metadata": {},
   "source": [
    "We can see that 107 columns / variables are almost constant. This means that 107 variables show predominantly one value for ~99% the observations of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b22fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.996286\n",
       "1    0.003714\n",
       "Name: ind_var31, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of observations showing each of the different values\n",
    "X_train['ind_var31'].value_counts() / float(len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8b4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then remove the features from training and test set\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcd9750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 263), (15000, 263))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of training and test set\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2113db",
   "metadata": {},
   "source": [
    "By removing constant and quasi-constant features, we reduced the feature space from 370 to 263. We can see that more than 100 features were removed from the present dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84284a",
   "metadata": {},
   "source": [
    "# Univariate selection methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f1773",
   "metadata": {},
   "source": [
    "There are 4 methods that fall under this category :-\n",
    "\n",
    "1.SelectKBest\n",
    "\n",
    "2.SelectPercentile\n",
    "\n",
    "3.SelectFpr, SelectFdr, or family wise error SelectFwe\n",
    "\n",
    "4.GenericUnivariateSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b28934",
   "metadata": {},
   "source": [
    "# SelectKBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05aef314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b6862dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the two best features\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151ea29",
   "metadata": {},
   "source": [
    "Thus, we have selected the two best features from the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20034923",
   "metadata": {},
   "source": [
    "# SelectPercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2b185",
   "metadata": {},
   "source": [
    "Select features according to a percentile of the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d06734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf73f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now select features based on top 10 percentile\n",
    "X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c1b9b",
   "metadata": {},
   "source": [
    "We can see that only 7 features lie on the top 10 percentile and hence we select them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7fe592",
   "metadata": {},
   "source": [
    "# Fisher Score (chi-square implementation) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977eb690",
   "metadata": {},
   "source": [
    "It is the chi-square implementation in scikit-learn. It computes chi-squared stats between each non-negative feature and class.\n",
    "\n",
    "This score should be used to evaluate categorical variables in a classification task. It compares the observed distribution of the different classes of target Y among the different categories of the feature, against the expected distribution of the target classes, regardless of the feature categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "503c91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5823af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create features and target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# convert to categorical data by converting data to integers\n",
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b66be980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Chi-Squared Statistics\n",
    "# select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c69d0f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6eebdc",
   "metadata": {},
   "source": [
    "We can see that the above code helps us to select the 2 best features based on Fisher score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b65e0",
   "metadata": {},
   "source": [
    "# ANOVA F-value For Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3a571",
   "metadata": {},
   "source": [
    "Compute the ANOVA F-value for the provided sample.\n",
    "\n",
    "If the features are categorical, we will calculate a chi-square statistic between each feature and the target vector. However, if the features are quantitative, we will compute the ANOVA F-value between each feature and the target vector.\n",
    "\n",
    "The F-value scores examine if, when we group the numerical feature by the target vector, the means for each group are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e03aabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "098bc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb55698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features With Best ANOVA F-Values\n",
    "\n",
    "# Create an SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3db1d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16697310",
   "metadata": {},
   "source": [
    "We can see that the above code helps us to select the 2 best features based on ANOVA F-Value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184b83b",
   "metadata": {},
   "source": [
    "# Correlation-Matrix with Heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25efaeb",
   "metadata": {},
   "source": [
    "Correlation is a measure of the linear relationship of 2 or more variables. Through correlation, we can predict one variable from the other.\n",
    "\n",
    "Good variables are highly correlated with the target.\n",
    "\n",
    "Correlated predictor variables provide redundant information.\n",
    "\n",
    "Variables should be correlated with the target but uncorrelated among themselves.\n",
    "\n",
    "Correlation Feature Selection evaluates subsets of features on the basis of the following hypothesis:\n",
    "\n",
    " \"Good feature subsets contain features highly correlated with the target, yet uncorrelated to each     other\".\n",
    "\n",
    "In this section, I will demonstrate how to select features based on correlation between two features. We can find features that are correlated with each other. By identifying these features, we can then decide which features we want to keep, and which ones we want to remove.\n",
    "\n",
    "Using Pearson correlation our returned coefficient values will vary between -1 and 1.\n",
    "\n",
    "If the correlation between two features is 0 this means that changing any of these two features will not affect the other.\n",
    "\n",
    "If the correlation between two features is greater than 0 this means that increasing the values in one feature will make increase also the values in the other feature (the closer the correlation coefficient is to 1 and the stronger is going to be this bond between the two different features).\n",
    "\n",
    "If the correlation between two features is less than 0 this means that increasing the values in one feature will make decrease the values in the other feature (the closer the correlation coefficient is to -1 and the stronger is going to be this relationship between the two different features).\n",
    "\n",
    "In this analysis we will check if the selected variables are highly correlated with each other. If they are, we would then need to keep just one of the correlated ones and drop the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "899a5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0efcc90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    4.9  3.0  1.4  0.2\n",
      "2    4.7  3.2  1.3  0.2\n",
      "3    4.6  3.1  1.5  0.2\n",
      "4    5.0  3.6  1.4  0.2\n",
      "..   ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3\n",
      "146  6.3  2.5  5.0  1.9\n",
      "147  6.5  3.0  5.2  2.0\n",
      "148  6.2  3.4  5.4  2.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert feature matrix into DataFrame\n",
    "df = pd.DataFrame(X)\n",
    "\n",
    "# View the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23301a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  1.000000 -0.117570  0.871754  0.817941\n",
      "1 -0.117570  1.000000 -0.428440 -0.366126\n",
      "2  0.871754 -0.428440  1.000000  0.962865\n",
      "3  0.817941 -0.366126  0.962865  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "609ebb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Correlation Heatmap of Iris Dataset')\n",
    "a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)           \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2001bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11757</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>-0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        1         2         3\n",
       "0 NaN -0.11757  0.871754  0.817941\n",
       "1 NaN      NaN -0.428440 -0.366126\n",
       "2 NaN      NaN       NaN  0.962865\n",
       "3 NaN      NaN       NaN       NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95b5c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bb212a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2\n",
      "0    5.1  3.5  1.4\n",
      "1    4.9  3.0  1.4\n",
      "2    4.7  3.2  1.3\n",
      "3    4.6  3.1  1.5\n",
      "4    5.0  3.6  1.4\n",
      "..   ...  ...  ...\n",
      "145  6.7  3.0  5.2\n",
      "146  6.3  2.5  5.0\n",
      "147  6.5  3.0  5.2\n",
      "148  6.2  3.4  5.4\n",
      "149  5.9  3.0  5.1\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop Marked Features\n",
    "df1 = df.drop(df.columns[to_drop], axis=1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce0698b",
   "metadata": {},
   "source": [
    "# Wrapper Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60c0a0",
   "metadata": {},
   "source": [
    "n wrapper methods, we try to use a subset of features and train a model using them. Based on the inferences that we draw from the previous model, we decide to add or remove features from the subset. The problem is essentially reduced to a search problem. These methods are usually computationally very expensive.\n",
    "\n",
    "Some common examples of wrapper methods are\n",
    "\n",
    "Forward selection,\n",
    "\n",
    "Backward elimination,\n",
    "\n",
    "Exhaustive feature selection,\n",
    "\n",
    "Recursive feature elimination.\n",
    "\n",
    "Recursive feature elimination with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb8280",
   "metadata": {},
   "source": [
    "# Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c024420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\snega\\anaconda3\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\snega\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98c185a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52b665e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\train.2.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19d396a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea586e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 37), (438, 37))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07d84888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  3\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1554cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 34), (438, 34))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removed correlated  features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6b20e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bca0faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   12.6s finished\n",
      "\n",
      "[2024-04-16 23:33:15] Features: 1/10 -- score: 0.6674319898715358[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   13.7s finished\n",
      "\n",
      "[2024-04-16 23:33:28] Features: 2/10 -- score: 0.7223040147837024[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   14.5s finished\n",
      "\n",
      "[2024-04-16 23:33:43] Features: 3/10 -- score: 0.7470257839832892[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   14.9s finished\n",
      "\n",
      "[2024-04-16 23:33:58] Features: 4/10 -- score: 0.764008409712139[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   16.1s finished\n",
      "\n",
      "[2024-04-16 23:34:14] Features: 5/10 -- score: 0.7701370806411404[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   17.1s finished\n",
      "\n",
      "[2024-04-16 23:34:31] Features: 6/10 -- score: 0.7712276318685164[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   19.4s finished\n",
      "\n",
      "[2024-04-16 23:34:51] Features: 7/10 -- score: 0.7950791167569694[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   32.1s finished\n",
      "\n",
      "[2024-04-16 23:35:23] Features: 8/10 -- score: 0.8251985396425804[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   33.6s finished\n",
      "\n",
      "[2024-04-16 23:35:57] Features: 9/10 -- score: 0.8413234994833103[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   37.6s finished\n",
      "\n",
      "[2024-04-16 23:36:34] Features: 10/10 -- score: 0.8520693852699125"
     ]
    }
   ],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(RandomForestRegressor(), \n",
    "           k_features=10, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=3)\n",
    "\n",
    "sfs1 = sfs1.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10af710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 6, 9, 14, 16, 17, 19, 22, 24)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96beca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OverallQual', 'OverallCond', 'YearBuilt', 'BsmtFinSF1', '2ndFlrSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'FullBath', 'KitchenAbvGr', 'GarageCars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[list(sfs1.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f21b4",
   "metadata": {},
   "source": [
    "We can see that forward feature selection results in the above columns being selected from all the given columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639b2bc",
   "metadata": {},
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e67fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  2.6min finished\n",
      "\n",
      "[2024-04-16 23:39:16] Features: 33/10 -- score: 0.8550565333880984[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  2.5min finished\n",
      "\n",
      "[2024-04-16 23:41:45] Features: 32/10 -- score: 0.8595027111825458[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  2.3min finished\n",
      "\n",
      "[2024-04-16 23:44:05] Features: 31/10 -- score: 0.8571352637068651[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  4.2min finished\n",
      "\n",
      "[2024-04-16 23:48:20] Features: 30/10 -- score: 0.8578241850534042[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# step backward feature elimination\n",
    "\n",
    "sfs1 = SFS(RandomForestRegressor(), \n",
    "           k_features=10, \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=3)\n",
    "\n",
    "sfs1 = sfs1.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcec506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[list(sfs1.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98461c0d",
   "metadata": {},
   "source": [
    "# LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\train.2.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba78ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22175e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features in the house dataset are in very\n",
    "# different scales, so it helps the regression to scale them\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12089099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, again I will train a Lasso Linear regression and select\n",
    "# the non zero features in one line.\n",
    "# bear in mind that the linear regression object from sklearn does\n",
    "# not allow for regularisation. So If you want to make a regularised\n",
    "# linear regression you need to import specifically \"Lasso\"\n",
    "# that is the l1 version of the linear regression\n",
    "# alpha is the penalisation here, so I set it high in order\n",
    "# to force the algorithm to shrink some coefficients\n",
    "\n",
    "sel_ = SelectFromModel(Lasso(alpha=100))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f55002",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with the selected features and print the outputs\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cfb9c",
   "metadata": {},
   "source": [
    "# Random Forest Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ba176",
   "metadata": {},
   "source": [
    "Random forests are one the most popular machine learning algorithms. They are so successful because they provide in general a good predictive performance, low overfitting and easy interpretability. This interpretability is given by the fact that it is straightforward to derive the importance of each variable on the tree decision. In other words, it is easy to compute how much each variable is contributing to the decision.\n",
    "\n",
    "Random forests consist of 4-12 hundred decision trees, each of them built over a random extraction of the observations from the dataset and a random extraction of the features. Not every tree sees all the features or all the observations, and this guarantees that the trees are de-correlated and therefore less prone to over-fitting. Each tree is also a sequence of yes-no questions based on a single or combination of features. At each node (this is at each question), the three divides the dataset into 2 buckets, each of them hosting observations that are more similar among themselves and different from the ones in the other bucket. Therefore, the importance of each feature is derived by how \"pure\" each of the buckets is.\n",
    "\n",
    "For classification, the measure of impurity is either the Gini impurity or the information gain/entropy. For regression the measure of impurity is variance. Therefore, when training a tree, it is possible to compute how much each feature decreases the impurity. The more a feature decreases the impurity, the more important the feature is. In random forests, the impurity decrease from each feature can be averaged across trees to determine the final importance of the variable.\n",
    "\n",
    "To give a better intuition, features that are selected at the top of the trees are in general more important than features that are selected at the end nodes of the trees, as generally the top splits lead to bigger information gains.\n",
    "\n",
    "Please see my kernel, Random Forest Classifier + Feature Importance - Section 13. Find important features with Random Forest model to know how to find important features using the random forest model.\n",
    "\n",
    "I will demonstrate this process using the mushroom classification dataset as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\snega\\Desktop\\python\\BIG DATA\\Feature selection\\mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare feature vector and target variable\n",
    "X = df.drop(['class'], axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X, prefix_sep='_')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature vector\n",
    "X2 = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the classifier to the training set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9327112",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d19a53",
   "metadata": {},
   "source": [
    "Decision Trees models which are based on ensembles (eg. Extra Trees and Random Forest) can be used to rank the importance of the different features. Knowing which features our model is giving most importance can be of vital importance to understand how our model is making it’s predictions (therefore making it more explainable). At the same time, we can get rid of the features which do not bring any benefit to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature importance\n",
    "\n",
    "plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feat_importances = pd.Series(clf.feature_importances_, index= X.columns)\n",
    "\n",
    "feat_importances.nlargest(7).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cae6c2",
   "metadata": {},
   "source": [
    "Now we know which features are most important in the Random Forest model, we can train our model just using these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e13fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
